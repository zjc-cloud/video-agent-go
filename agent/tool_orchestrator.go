package agent

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"time"
	"video-agent-go/config"
	"video-agent-go/model"
)

// ToolBasedOrchestrator åŸºäºå·¥å…·çš„LLMç¼–æ’å™¨
type ToolBasedOrchestrator struct {
	toolRegistry  *ToolRegistry
	context       *ToolOrchestrationContext
	maxIterations int
}

// ToolOrchestrationContext å·¥å…·ç¼–æ’ä¸Šä¸‹æ–‡
type ToolOrchestrationContext struct {
	TaskID       string                 `json:"task_id"`
	UserRequest  string                 `json:"user_request"`
	CurrentState map[string]interface{} `json:"current_state"`
	ToolCalls    []CompletedToolCall    `json:"tool_calls"`
	Resources    map[string]string      `json:"resources"`
}

// CompletedToolCall å®Œæˆçš„å·¥å…·è°ƒç”¨è®°å½•
type CompletedToolCall struct {
	Call      ToolCall    `json:"call"`
	Result    *ToolResult `json:"result"`
	Timestamp int64       `json:"timestamp"`
	Duration  int64       `json:"duration_ms"`
}

// LLMResponse LLMçš„å“åº”ç»“æ„
type LLMResponse struct {
	Role      string     `json:"role"`
	Content   string     `json:"content,omitempty"`
	ToolCalls []ToolCall `json:"tool_calls,omitempty"`
}

// ChatMessage èŠå¤©æ¶ˆæ¯ç»“æ„
type ChatMessage struct {
	Role       string     `json:"role"`
	Content    string     `json:"content,omitempty"`
	ToolCalls  []ToolCall `json:"tool_calls,omitempty"`
	ToolCallID string     `json:"tool_call_id,omitempty"`
	Name       string     `json:"name,omitempty"`
}

// NewToolBasedOrchestrator åˆ›å»ºåŸºäºå·¥å…·çš„ç¼–æ’å™¨
func NewToolBasedOrchestrator() *ToolBasedOrchestrator {
	registry := NewToolRegistry()

	// æ³¨å†Œæ‰€æœ‰å¯ç”¨å·¥å…·
	registry.RegisterTool(&ContentAnalysisTool{})
	registry.RegisterTool(&ScriptGenerationTool{})
	registry.RegisterTool(&ImageGenerationTool{})
	registry.RegisterTool(&VoiceGenerationTool{})
	registry.RegisterTool(&QualityCheckTool{})
	registry.RegisterTool(&VideoRenderTool{})

	return &ToolBasedOrchestrator{
		toolRegistry:  registry,
		maxIterations: 10, // é˜²æ­¢æ— é™å¾ªç¯
	}
}

// ProcessTask å¤„ç†ä»»åŠ¡ - åŸºäºå·¥å…·çš„æ™ºèƒ½ç¼–æ’
func (o *ToolBasedOrchestrator) ProcessTask(taskID string, userRequest string) (*model.ScriptOutput, error) {
	// åˆå§‹åŒ–ä¸Šä¸‹æ–‡
	o.context = &ToolOrchestrationContext{
		TaskID:       taskID,
		UserRequest:  userRequest,
		CurrentState: make(map[string]interface{}),
		ToolCalls:    make([]CompletedToolCall, 0),
		Resources:    make(map[string]string),
	}

	log.Printf("ğŸš€ Starting tool-based orchestration for task: %s", taskID)

	// åˆå§‹åŒ–æ¶ˆæ¯å†å²
	messages := []ChatMessage{
		{
			Role:    "system",
			Content: o.buildSystemPrompt(),
		},
		{
			Role:    "user",
			Content: fmt.Sprintf("Please help me create a video based on this request: \"%s\"", userRequest),
		},
	}

	// ä¸LLMè¿›è¡Œå¤šè½®å¯¹è¯ï¼Œç›´åˆ°ä»»åŠ¡å®Œæˆ
	for iteration := 0; iteration < o.maxIterations; iteration++ {
		log.Printf("ğŸ”„ Iteration %d: Consulting LLM for next action", iteration+1)

		// è°ƒç”¨LLMè·å–ä¸‹ä¸€æ­¥åŠ¨ä½œ
		response, err := o.callLLMWithTools(messages)
		if err != nil {
			return nil, fmt.Errorf("LLM call failed: %v", err)
		}

		// å°†LLMå“åº”æ·»åŠ åˆ°æ¶ˆæ¯å†å²
		messages = append(messages, ChatMessage{
			Role:      "assistant",
			Content:   response.Content,
			ToolCalls: response.ToolCalls,
		})

		// æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
		if len(response.ToolCalls) == 0 {
			// LLMè®¤ä¸ºä»»åŠ¡å·²å®Œæˆ
			log.Printf("âœ… LLM indicates task completion")
			break
		}

		// æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
		for _, toolCall := range response.ToolCalls {
			result, err := o.executeToolCall(toolCall)
			if err != nil {
				log.Printf("âŒ Tool call failed: %v", err)
				// å°†é”™è¯¯ä¿¡æ¯æ·»åŠ åˆ°æ¶ˆæ¯å†å²
				messages = append(messages, ChatMessage{
					Role:       "tool",
					Content:    fmt.Sprintf("Tool execution failed: %v", err),
					ToolCallID: toolCall.ID,
					Name:       toolCall.Function.Name,
				})
				continue
			}

			// å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
			resultJSON, _ := json.Marshal(result.Data)
			messages = append(messages, ChatMessage{
				Role:       "tool",
				Content:    string(resultJSON),
				ToolCallID: toolCall.ID,
				Name:       toolCall.Function.Name,
			})

			// æ›´æ–°ä¸Šä¸‹æ–‡çŠ¶æ€
			o.updateContextFromToolResult(toolCall.Function.Name, result)
		}
	}

	// æ„å»ºæœ€ç»ˆç»“æœ
	return o.buildFinalResult(), nil
}

// buildSystemPrompt æ„å»ºç³»ç»Ÿæç¤ºè¯
func (o *ToolBasedOrchestrator) buildSystemPrompt() string {
	toolsDescription := o.buildToolsDescription()

	return fmt.Sprintf(`You are an intelligent video generation orchestrator. Your job is to help users create videos by using the available tools strategically.

AVAILABLE TOOLS:
%s

INSTRUCTIONS:
1. Analyze the user's request to understand what type of video they want
2. Use tools step by step to gather information, generate content, and create the final video
3. Always start with content analysis to understand the requirements
4. Choose tools based on the specific needs of each request
5. Check quality before finalizing
6. Only indicate completion when you have successfully created a video file

DECISION MAKING PRINCIPLES:
- For educational content: prioritize accuracy and clarity
- For commercial content: focus on visual impact and persuasion  
- For entertainment: emphasize creativity and engagement
- Always consider the target audience
- Use quality checks for important content
- Be efficient but don't compromise on quality

You must use tools to accomplish tasks. Do not try to generate content directly.`, toolsDescription)
}

// buildToolsDescription æ„å»ºå·¥å…·æè¿°
func (o *ToolBasedOrchestrator) buildToolsDescription() string {
	var descriptions []string

	for _, tool := range o.toolRegistry.GetAllTools() {
		description := fmt.Sprintf("- %s: %s", tool.GetName(), tool.GetDescription())
		descriptions = append(descriptions, description)
	}

	return fmt.Sprintf("%s", descriptions)
}

// callLLMWithTools è°ƒç”¨LLMå¹¶æ”¯æŒå·¥å…·è°ƒç”¨
func (o *ToolBasedOrchestrator) callLLMWithTools(messages []ChatMessage) (*LLMResponse, error) {
	// æ„å»ºOpenAI APIè¯·æ±‚
	reqBody := map[string]interface{}{
		"model":       "gpt-4-turbo-preview",
		"messages":    messages,
		"tools":       o.toolRegistry.GetToolsSchema(),
		"tool_choice": "auto", // è®©LLMè‡ªåŠ¨å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return nil, err
	}

	req, err := http.NewRequest("POST", "https://api.openai.com/v1/chat/completions", bytes.NewBuffer(jsonData))
	if err != nil {
		return nil, err
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+config.AppConfig.API.OpenAIKey)

	client := &http.Client{Timeout: 60 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, err
	}

	var openAIResp struct {
		Choices []struct {
			Message LLMResponse `json:"message"`
		} `json:"choices"`
	}

	if err := json.Unmarshal(body, &openAIResp); err != nil {
		return nil, err
	}

	if len(openAIResp.Choices) == 0 {
		return nil, fmt.Errorf("no response from OpenAI")
	}

	return &openAIResp.Choices[0].Message, nil
}

// executeToolCall æ‰§è¡Œå·¥å…·è°ƒç”¨
func (o *ToolBasedOrchestrator) executeToolCall(toolCall ToolCall) (*ToolResult, error) {
	startTime := time.Now()

	result, err := o.toolRegistry.ExecuteToolCall(toolCall)

	duration := time.Since(startTime).Milliseconds()

	// è®°å½•å·¥å…·è°ƒç”¨
	completedCall := CompletedToolCall{
		Call:      toolCall,
		Result:    result,
		Timestamp: startTime.Unix(),
		Duration:  duration,
	}

	o.context.ToolCalls = append(o.context.ToolCalls, completedCall)

	return result, err
}

// updateContextFromToolResult ä»å·¥å…·ç»“æœæ›´æ–°ä¸Šä¸‹æ–‡
func (o *ToolBasedOrchestrator) updateContextFromToolResult(toolName string, result *ToolResult) {
	if !result.Success {
		return
	}

	// æ ¹æ®å·¥å…·ç±»å‹æ›´æ–°ä¸åŒçš„çŠ¶æ€
	switch toolName {
	case "analyze_content":
		if analysis, ok := result.Data.(map[string]interface{}); ok {
			o.context.CurrentState["content_analysis"] = analysis
		}
	case "generate_script":
		if script, ok := result.Data.(map[string]interface{}); ok {
			o.context.CurrentState["script"] = script
		}
	case "generate_images":
		if images, ok := result.Data.(map[string]interface{}); ok {
			o.context.CurrentState["images"] = images
		}
	case "generate_voice":
		if audio, ok := result.Data.(map[string]interface{}); ok {
			o.context.CurrentState["audio"] = audio
		}
	case "render_video":
		if video, ok := result.Data.(map[string]interface{}); ok {
			o.context.CurrentState["final_video"] = video
			if videoFile, ok := video["video_file"].(string); ok {
				o.context.Resources["final_video"] = videoFile
			}
		}
	case "check_quality":
		if quality, ok := result.Data.(map[string]interface{}); ok {
			o.context.CurrentState["quality_check"] = quality
		}
	}
}

// buildFinalResult æ„å»ºæœ€ç»ˆç»“æœ
func (o *ToolBasedOrchestrator) buildFinalResult() *model.ScriptOutput {
	// ä»ä¸Šä¸‹æ–‡çŠ¶æ€æ„å»ºæœ€ç»ˆè¾“å‡º
	result := &model.ScriptOutput{
		TaskID: o.context.TaskID,
		Status: "completed",
	}

	// æå–è„šæœ¬ä¿¡æ¯
	if script, ok := o.context.CurrentState["script"].(map[string]interface{}); ok {
		if title, ok := script["title"].(string); ok {
			result.Title = title
		}
	}

	// æå–æœ€ç»ˆè§†é¢‘è·¯å¾„
	if finalVideo, ok := o.context.Resources["final_video"]; ok {
		result.Final = finalVideo
	}

	return result
}

// GetExecutionLog è·å–æ‰§è¡Œæ—¥å¿—
func (o *ToolBasedOrchestrator) GetExecutionLog() []CompletedToolCall {
	if o.context == nil {
		return []CompletedToolCall{}
	}
	return o.context.ToolCalls
}

// GetCurrentState è·å–å½“å‰çŠ¶æ€
func (o *ToolBasedOrchestrator) GetCurrentState() map[string]interface{} {
	if o.context == nil {
		return make(map[string]interface{})
	}
	return o.context.CurrentState
}
